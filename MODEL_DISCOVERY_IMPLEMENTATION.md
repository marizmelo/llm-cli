# Model Discovery Implementation

## Overview

This document describes the implementation of automatic model discovery and updates for the enhanced provider system. The system now dynamically fetches model lists from provider APIs and keeps the configuration up-to-date.

## ğŸ¯ **Key Features**

### **1. Automatic Model Discovery**
- **API Integration**: Fetches model lists directly from provider APIs
- **Caching System**: 24-hour cache to avoid excessive API calls
- **Smart Updates**: Only updates when cache expires or on demand
- **Safe Updates**: Creates backups before modifying configuration

### **2. Provider-Specific Implementations**
- **OpenAI**: `/v1/models` endpoint with GPT and embedding model filtering
- **Anthropic**: `/v1/models` endpoint with Claude model filtering
- **Google**: Curated list (stable, manually updated)
- **Ollama**: Local `/api/tags` endpoint for installed models

### **3. New Commands**
- `/provider discover <provider>` - Discover models for specific provider
- `/provider update` - Update all providers that need updating
- Enhanced `/provider status` - Shows model update status

## ğŸ”§ **Technical Implementation**

### **ModelDiscovery Class**

**Location**: `packages/cli/src/config/modelDiscovery.ts`

**Key Methods**:
- `discoverModels(provider, apiKey)` - Main discovery method
- `updateProviderConfig(provider, apiKey)` - Updates configuration
- `shouldUpdateModels(provider)` - Checks if update is needed
- `getUpdateStatus()` - Gets status for all providers

### **API Integration**

#### **OpenAI Models**
```typescript
const response = await fetch(`${baseUrl}/models`, {
  headers: {
    'Authorization': `Bearer ${key}`,
    'Content-Type': 'application/json'
  }
});

const models = data.data
  .filter((model: any) => 
    model.id.startsWith('gpt-') || 
    model.id.startsWith('text-') ||
    model.id.includes('embedding')
  )
  .map((model: any) => model.id)
  .sort();
```

#### **Anthropic Models**
```typescript
const response = await fetch(`${baseUrl}/v1/models`, {
  headers: {
    'x-api-key': key,
    'anthropic-version': '2023-06-01',
    'Content-Type': 'application/json'
  }
});

const models = data.data
  .filter((model: any) => model.id.startsWith('claude-'))
  .map((model: any) => model.id)
  .sort();
```

#### **Ollama Models**
```typescript
const response = await fetch(`${baseUrl}/api/tags`, {
  method: 'GET',
  headers: {
    'Content-Type': 'application/json'
  }
});

const models = data.models
  .map((model: { name: string }) => model.name)
  .sort();
```

### **Caching System**

**Cache Location**: `.gemini/model-cache.json`

**Cache Duration**: 24 hours

**Cache Structure**:
```json
{
  "openai": {
    "success": true,
    "models": ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
    "lastUpdated": 1704067200000
  },
  "anthropic": {
    "success": true,
    "models": ["claude-3-opus-20240229", "claude-3-sonnet-20240229"],
    "lastUpdated": 1704067200000
  }
}
```

### **Configuration Updates**

**Backup System**: Creates timestamped backups before updates
**Update Process**:
1. Fetch fresh model list from API
2. Compare with current configuration
3. Create backup of current config
4. Update models list
5. Add `lastUpdated` timestamp
6. Write updated configuration

## ğŸš€ **User Experience**

### **Discover Models for Specific Provider**

```bash
/provider discover openai
```

**Output**:
```
ğŸ” Discovering models for OpenAI...

âœ… Successfully updated models for openai

ğŸ“‹ Available models (12):
  â€¢ gpt-4
  â€¢ gpt-4-1106-preview
  â€¢ gpt-4-turbo
  â€¢ gpt-4-turbo-preview
  â€¢ gpt-3.5-turbo
  â€¢ gpt-3.5-turbo-16k
  â€¢ text-embedding-ada-002
  â€¢ text-embedding-3-large
  â€¢ text-embedding-3-small
```

### **Update All Providers**

```bash
/provider update
```

**Output**:
```
ğŸ”„ Updating models for 2 provider(s)...

âœ… openai: Successfully updated models for openai
âŒ anthropic: Failed to update models for anthropic. Check your API key and try again.
```

### **Check Update Status**

```bash
/provider status
```

**Output**:
```
ğŸ“Š Current Provider Status:

  Provider: OpenAI
  Auth Type: USE_OPENAI
  Model: gpt-4
  Configuration: âœ… Complete

ğŸ“‹ Environment Variables:
  OPENAI_API_KEY: ***abcd
  OPENAI_MODEL: gpt-4

ğŸ“ .env file: /path/to/project/.gemini/.env

ğŸ”„ Model Update Status:
  âœ… openai: Up to date (2024-01-15)
  ğŸ”„ anthropic: Needs update (2024-01-10)
  âœ… google: Up to date (2024-01-14)
  ğŸ”„ ollama: Needs update (Never)
```

## ğŸ“‹ **Configuration Schema**

### **Updated Provider Configuration**

```json
{
  "providers": {
    "openai": {
      "name": "OpenAI",
      "description": "GPT-4, GPT-3.5-turbo, and other models",
      "authType": "USE_OPENAI",
      "requiredEnvVars": ["OPENAI_API_KEY"],
      "optionalEnvVars": ["OPENAI_MODEL", "OPENAI_BASE_URL"],
      "defaultModel": "gpt-4",
      "apiKeyFormat": "sk-*",
      "apiKeyUrl": "https://platform.openai.com/api-keys",
      "models": ["gpt-4", "gpt-4-turbo", "gpt-4o", "gpt-3.5-turbo"],
      "lastUpdated": 1704067200000
    }
  }
}
```

**New Fields**:
- `lastUpdated`: Timestamp of last model discovery
- `models`: Dynamically updated model list

## ğŸ”„ **Update Workflow**

### **Automatic Updates**
1. **Cache Check**: Check if cache is expired (24 hours)
2. **API Call**: Fetch fresh model list if needed
3. **Comparison**: Compare with current configuration
4. **Update**: Update configuration if changes detected
5. **Backup**: Create backup before changes
6. **Cache**: Store result in cache

### **Manual Updates**
1. **Command**: User runs `/provider discover <provider>`
2. **Validation**: Check if provider is configured
3. **API Call**: Force fresh API call (ignore cache)
4. **Update**: Update configuration with new models
5. **Feedback**: Show added/removed models

## ğŸ›¡ï¸ **Safety Features**

### **Error Handling**
- **API Failures**: Graceful fallback to cached data
- **Network Issues**: Timeout and retry logic
- **Invalid Responses**: Data validation and filtering
- **Configuration Errors**: Backup restoration capability

### **Backup System**
- **Automatic Backups**: Before any configuration changes
- **Timestamped Files**: `.gemini/providers.json.backup.{timestamp}`
- **Restoration**: Manual restore from backup if needed

### **Cache Management**
- **Expiration**: 24-hour cache duration
- **Invalidation**: Manual cache clearing
- **Fallback**: Use cached data if API fails

## ğŸ“Š **Monitoring and Status**

### **Update Status Tracking**
- **Last Updated**: Timestamp of last successful update
- **Update Needed**: Boolean flag for cache expiration
- **Provider Status**: Individual provider update status
- **Error Tracking**: Failed update attempts

### **Status Display**
- **Visual Indicators**: âœ… for up-to-date, ğŸ”„ for needs update
- **Date Formatting**: Human-readable timestamps
- **Provider Names**: Clear provider identification
- **Error Messages**: Specific error information

## ğŸ¯ **Benefits**

### **For Users**
- **Always Current**: Latest model options available
- **Automatic Updates**: No manual configuration needed
- **Clear Status**: Know when models were last updated
- **Safe Updates**: Automatic backups protect configuration

### **For Developers**
- **Extensible**: Easy to add new providers
- **Maintainable**: Centralized discovery logic
- **Reliable**: Robust error handling and fallbacks
- **Testable**: Clear separation of concerns

### **For Operations**
- **Reduced Maintenance**: Automatic model list updates
- **Better UX**: Users always see latest options
- **Monitoring**: Clear status of update health
- **Recovery**: Backup system for configuration safety

## ğŸ”® **Future Enhancements**

### **Potential Improvements**
1. **Scheduled Updates**: Automatic background updates
2. **Model Metadata**: Additional model information (capabilities, pricing)
3. **Version Tracking**: Track model version changes
4. **Notification System**: Alert users to new models
5. **Bulk Operations**: Update multiple providers simultaneously

### **Extensibility**
- **Custom Providers**: Easy to add new AI services
- **Plugin System**: Third-party provider integrations
- **API Versioning**: Support for different API versions
- **Rate Limiting**: Respect provider API limits

## âœ… **Testing**

### **Manual Testing Checklist**
- [ ] `/provider discover` works for all providers
- [ ] `/provider update` updates only needed providers
- [ ] `/provider status` shows correct update status
- [ ] Cache expiration works correctly
- [ ] Backup files are created before updates
- [ ] Error handling works for API failures
- [ ] Configuration updates are applied correctly

### **Integration Testing**
- [ ] Model discovery works with existing authentication
- [ ] Updated models are available in provider switching
- [ ] Cache system doesn't interfere with normal operation
- [ ] Backup system preserves configuration integrity

## ğŸ‰ **Success Criteria**

The model discovery system successfully:

1. âœ… **Fetches model lists** from provider APIs
2. âœ… **Caches results** to minimize API calls
3. âœ… **Updates configuration** automatically
4. âœ… **Creates backups** before changes
5. âœ… **Provides status** information
6. âœ… **Handles errors** gracefully
7. âœ… **Maintains backward compatibility**

This implementation transforms the static provider configuration into a dynamic, self-updating system that keeps users informed of the latest available models while maintaining safety and reliability.
