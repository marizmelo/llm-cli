# LLM CLI

LLM-CLI is a command-line AI assistant that's a fork of Gemini Cli. Unlike its predecessor, LLM-CLI is a multi-provider tool that supports Gemini, OpenAI, Anthropic Claude, Ollama, and more, making it a powerful agent for coding. This means you can now use all of Gemini Cliâ€™s powerful features with your preferred large language modelâ€”whether it's running in the cloud or locally.

## Installation

```bash
npm install -g @marizmelo/llm-cli
```

## Usage

```bash
llm-cli
```

For non-interactive mode:
```bash
llm-cli --prompt "What is 2+2?"
```

## Features

- ğŸ¤– Multi-provider support (OpenAI, Anthropic, Ollama, Gemini)
- ğŸ”§ Interactive CLI interface with full tool/function support
- ğŸ“ Context-aware file processing
- ğŸ”Œ Extensible with custom commands
- ğŸ¯ Provider-specific model switching
- ğŸ’¾ Memory and context management
- ğŸ”‘ Secure API key management with persistent settings
- ğŸ› ï¸ Full tool/function calling support for OpenAI and Anthropic

## What's New in v0.1.0

### Enhanced Provider Support
- **OpenAI & Anthropic Tool Support**: Both providers now have full function/tool calling capabilities, allowing them to use all available CLI tools (file operations, shell commands, web searches, etc.)
- **Persistent API Key Management**: API keys are now saved to settings and automatically synced to environment variables on startup
- **Improved Provider Setup**: Simplified setup process with `/provider setup <provider> <api-key>` command
- **Better Error Handling**: Fixed streaming response issues and improved error messages

### Provider Setup

#### Quick Setup (New Method)
```bash
# Setup providers with persistent API keys
llm-cli
/provider setup openai sk-your-api-key
/provider setup anthropic sk-ant-your-api-key
/provider switch openai
```

#### Ollama (Local)
```bash
# Install Ollama first, then:
llm-cli
/provider switch ollama
```

#### Traditional Setup (Environment Variables)
```bash
# Still supported for backward compatibility
export OPENAI_API_KEY="your-api-key"
export ANTHROPIC_API_KEY="your-api-key"
llm-cli
```

## Documentation

For full documentation, visit: https://github.com/marizmelo/llm-cli

## License

Apache-2.0